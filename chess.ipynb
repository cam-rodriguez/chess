{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chess",
      "provenance": [],
      "authorship_tag": "ABX9TyNSSvay9e1GIt/F01C3/RnU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cam-rodriguez/chess/blob/main/chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Seeing where I lose, win, and draw in online chess games, and how often.**\n",
        "#### (*AKA, playing with [chess.com](https://chess.com) data in Python.*) "
      ],
      "metadata": {
        "id": "0YW-NWRYvm0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal here is to use the data downloaded from chess.com archives of my games, make sense of it, and then visualize it in a heatmap format. If you think about it, a chessboard is just an array, and from an array, you can make a heatmap of frequencies!\n",
        "\n",
        "\n",
        "\n",
        "Chess game data is kept in a **pgn** file, which is effectively a text file with some headers that could just be JSON but isn't. For the sake of this viz, I'm aiming to have it converted to a CSV, because it plays the nicest with Sheets and Datawrapper. "
      ],
      "metadata": {
        "id": "ORcaIshRwDlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FUCK i forgot how much python syntax is different than sql and it's different than java too lmfao"
      ],
      "metadata": {
        "id": "a0qDS_J8J2is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## what a time to be alive"
      ],
      "metadata": {
        "id": "ARWcgQ5fJ6Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First: convert files from PGN to CSV.\n",
        "Here, I'll be using the \"pgn2data\" library (github [here](https://https://github.com/zq99/pgn2data)), which is built off the [python-chess](https://https://github.com/niklasf/python-chess) library. It allows me to pretty easily convert between PGN and CSV, which is the whole point of this.\n",
        "\n",
        "The library splits the PGN file into two CSV files: one that breaks down the game info (_game_info.csv) and one that breaks down each individual move (_moves.csv)."
      ],
      "metadata": {
        "id": "csgMHui5woz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pgn2data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxDmSOlAKF1W",
        "outputId": "4bd9ad62-caf8-4261-c082-8d6d0a18e42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pgn2data\n",
            "  Downloading pgn2data-0.0.7-py3-none-any.whl (29 kB)\n",
            "Collecting chess\n",
            "  Downloading chess-1.9.2-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pgn2data) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pgn2data) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pgn2data) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pgn2data) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pgn2data) (1.15.0)\n",
            "Installing collected packages: chess, pgn2data\n",
            "Successfully installed chess-1.9.2 pgn2data-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from converter.pgn_data import PGNData as pgn"
      ],
      "metadata": {
        "id": "fWONx2HoJ7xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# an example of how to use this code is available on the project homepage linked above!\n",
        "pgn_data = pgn(\"games.pgn\")\n",
        "result = pgn_data.export()\n",
        "result.print_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BVQeA3LKLh-",
        "outputId": "0f48aaae-169b-4433-c6f2-89d6648079b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is complete: True\n",
            "games file: games_game_info.csv | size: 10786\n",
            "moves file: games_moves.csv | size: 1032235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result.is_complete:\n",
        "  games_df = result.get_games_df()\n",
        "  moves_df = result.get_moves_df()\n",
        "  combined_df = result.get_combined_df()\n",
        "\n",
        "print(games_df.head())\n",
        "print(moves_df.head())\n",
        "print(combined_df.head())"
      ],
      "metadata": {
        "id": "xxw_xPnbKkQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## viola"
      ],
      "metadata": {
        "id": "lVZRxeGQR_Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now: write a function to be able to convert more of the files, because you don't want to use an API and this is just easier in your mind.\n",
        "don't question me this is my personal project not yours"
      ],
      "metadata": {
        "id": "9V0fKITRxa_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tocsv(file):\n",
        "  data = pgn(file)\n",
        "  result = data.export()\n",
        "  result.print_summary()\n",
        "  \n",
        "  if result.is_complete:\n",
        "    games_df = result.get_games_df()\n",
        "    moves_df = result.get_moves_df()\n",
        "    combined_df = result.get_combined_df()\n",
        "\n",
        "  print(games_df.head())\n",
        "  print(moves_df.head())\n",
        "  print(combined_df.head())"
      ],
      "metadata": {
        "id": "OSCv5UCnlfq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tocsv(\"games_Aug_Jul21.pgn\") # testing with a file that has games from July-August 2021"
      ],
      "metadata": {
        "id": "B-TiZ7FImazV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tocsv(\"games_Dec_Sept21.pgn\")\n",
        "tocsv(\"games_Jul21.pgn\")\n",
        "tocsv(\"games_Jul21_2.pgn\")\n",
        "tocsv(\"games_Jun21.pgn\")\n",
        "tocsv(\"games_Sept_Aug21_1.pgn\")"
      ],
      "metadata": {
        "id": "5JbGXCxEmbXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Woah, that's a lot of files! Let's make it so there aren't as many!\n",
        "Okay, now I'm compressing all of the CSV game files into each other -- that is, compressing all the _game_info.csv files into one, and all the _moves.csv files into one.\n",
        "\n",
        "Using os and glob here. Thanks, stack overflow!\n"
      ],
      "metadata": {
        "id": "fbuQuibCvXnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "UxBMgs8Eu_6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## game info\n",
        "\n",
        "# setting the path for joining multiple files\n",
        "game_info = os.path.join(\"*_game_info.csv\")\n",
        "\n",
        "# list of merged files returned\n",
        "game_info = glob.glob(game_info)\n",
        "print(\"Game Info big csv :)\");\n",
        "\n",
        "# joining files with concat and read_csv\n",
        "game_info_df = pd.concat(map(pd.read_csv, game_info), ignore_index=True)\n",
        "print(game_info_df)\n",
        "\n",
        "# export to big csv\n",
        "game_info_df.to_csv(\"game_info_all\", index=False)"
      ],
      "metadata": {
        "id": "lPv14tZIzrIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## moves\n",
        "moves = os.path.join(\"*_moves.csv\")\n",
        "moves = glob.glob(moves)\n",
        "moves_df = pd.concat(map(pd.read_csv, moves), ignore_index=True)\n",
        "print(moves_df)\n",
        "\n",
        "moves_df.to_csv(\"moves_all\", index=False)"
      ],
      "metadata": {
        "id": "xSR4TmHeMRby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hahaha nice! :) now we took a LOT of files and turned it into only two. which is great! \n",
        "\n",
        "now i'm going to take the data into sheets (LINK TK) and see what i can do with it and what might need to be cleaned before I can play with it here, because like fucking hell I'm going to play with that here"
      ],
      "metadata": {
        "id": "7XuHBzJXNoWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YVYyc94UN_ha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}